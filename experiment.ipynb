{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Where the actual experiment happens!",
   "id": "459620ae91a86e79"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "#do necessary imports\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from rean.utils import make_run_dir, to_serializable\n",
    "from rean.data.Dataset import make_datasets\n",
    "from rean.models.CNN import PlainCNN\n",
    "from rean.models.P4 import P4CNN\n",
    "from rean.models.RelaxedP4 import RelaxedP4CNN\n",
    "from rean.train import train_full, evaluate\n",
    "from rean.plot import LossPlot\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "id": "c2574f9b77488830"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#some params that should be the same across all experimental runs\n",
    "\n",
    "group_order = 4\n",
    "hidden_dim = 8\n",
    "out_channels = hidden_dim\n",
    "classes = 10\n",
    "kernel_size = 3\n",
    "num_gconvs = 4\n",
    "num_epochs = 2\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "gamma = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n"
   ],
   "id": "505361abe207d126"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Experiment Running Loop #",
   "id": "c5f171478b923a65"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#test full loop\n",
    "models = ['PlainCNN', 'P4CNN', 'RelaxedP4CNN']\n",
    "noise_types = ['none']\n",
    "stds = [0.1, 0.2]\n",
    "\n",
    "for model_name in models:\n",
    "    for noise_type in noise_types:\n",
    "        for i, std in enumerate(stds):\n",
    "            if noise_type == 'none':\n",
    "                if i != 0: #only run noiseless once\n",
    "                    continue\n",
    "                train_noise = None\n",
    "                noise_params = {\"mean\":0, \"std\":0, 'gamma':0}\n",
    "\n",
    "            else:\n",
    "                train_noise = noise_type\n",
    "                test_noise = noise_type #could be none?\n",
    "                noise_params = {'mean': 0, 'std': std, 'gamma': gamma}\n",
    "            #make datasets\n",
    "            train_ds, val_ds, test_ds, in_channels = make_datasets(train_noise=train_noise,\n",
    "                                                            noise_params=noise_params,\n",
    "                                                            group_order=group_order)\n",
    "            #for now to make faster:\n",
    "            train_ds = torch.utils.data.Subset(train_ds, range(0, 1000))\n",
    "            #train model\n",
    "            run_data, best_model = train_full(model_name=model_name,\n",
    "                          train_ds=train_ds,\n",
    "                          val_ds=val_ds,\n",
    "                          in_channels=in_channels,\n",
    "                          hidden_dim=hidden_dim,\n",
    "                          out_channels=out_channels,\n",
    "                          classes=classes,\n",
    "                          num_gconvs=num_gconvs,\n",
    "                          kernel_size=kernel_size,\n",
    "                          group_order=group_order,\n",
    "                          num_epochs=num_epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          learning_rate=learning_rate,\n",
    "                          device=device)\n",
    "            run_data['noise_type'] = noise_type\n",
    "            run_data['std'] = std\n",
    "\n",
    "            run_dir = make_run_dir(model_name, noise_type, noise_params = noise_params, learning_rate = learning_rate)\n",
    "            with open(run_dir / \"run_data.json\", \"w\") as f:\n",
    "                json.dump(run_data, f, default = to_serializable, indent=2)\n",
    "\n",
    "            #test the model\n",
    "            test_loader = torch.utils.data.DataLoader(test_ds, batch_size=batch_size, shuffle=False, pin_memory =True)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            test_loss, test_acc = evaluate(best_model,  device, test_loader, criterion = criterion)\n",
    "            test = {\n",
    "                \"test_loss\": test_loss,\n",
    "                \"test_acc\": test_acc\n",
    "            }\n",
    "            print(f\"Test Loss: {test_loss}, Test Acc: {test_acc}\")\n",
    "            with open(run_dir / \"test_data.json\", \"w\") as f:\n",
    "                json.dump(test, f, default = to_serializable, indent=2)\n",
    "\n"
   ],
   "id": "78e5ef70973b81ce"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Plotting #\n",
   "id": "49af4e72ff275239"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#first, plot the performance of all 3 models on the baseline test set, on two sets of axes: one for train, one for validation\n",
    "fig, (train_ax, val_ax) = plt.subplots(1,2)\n",
    "runs = []\n",
    "tests = []\n",
    "for model_name in models:\n",
    "    runpath = Path(f\"./runs/{model_name}_none_std0_gamma0_lr{learning_rate}\")\n",
    "\n",
    "    #load the rundata in from the json\n",
    "    rundatapath = runpath / \"run_data.json\"\n",
    "    testdatapath = runpath / \"test_data.json\"\n",
    "    with rundatapath.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        run_data = json.load(f)\n",
    "    with testdatapath.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        test_data = json.load(f)\n",
    "    run_data.update(test_data)\n",
    "    runs.append(run_data)\n",
    "    tests.append(test_data)\n",
    "\n",
    "#make loss plots\n",
    "train_ax = LossPlot(train_ax, runs, labels = [\"model_name\"], title = \"Training Loss\", val = False)\n",
    "val_ax = LossPlot(val_ax, runs, labels = ['model_name'], title = \"Validation Loss\", train = False)\n",
    "fig.tight_layout()\n",
    "fig.suptitle(\"Training and Validation Loss, Baseline (No Noise) Experiments\", y=1.02)\n",
    "fig.savefig(\"baseline_loss_plots.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "cd9676f8c10d0ad3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# do the same for each noise type, but plotting both std runs on the same axes\n",
    "#so, each axes object will have 6 lines: 3 models x 2 stds\n",
    "noise_types = ['iso', 'aniso']\n",
    "for noise_type in noise_types:\n",
    "    fig, (train_ax, val_ax) = plt.subplots(1,2)\n",
    "    runs = []\n",
    "    tests = []\n",
    "    for model_name in models:\n",
    "        for std in stds:\n",
    "            runpath = Path(f\"./runs/{model_name}_{noise_type}_std{std}_gamma{gamma}_lr{learning_rate}\")\n",
    "\n",
    "            #load the rundata in from the json\n",
    "            rundatapath = runpath / \"run_data.json\"\n",
    "            testdatapath = runpath / \"test_data.json\"\n",
    "            with rundatapath.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                run_data = json.load(f)\n",
    "            with testdatapath.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                test_data = json.load(f)\n",
    "            run_data.update(test_data)\n",
    "            runs.append(run_data)\n",
    "            tests.append(test_data)\n",
    "\n",
    "    #make loss plots\n",
    "    train_ax = LossPlot(train_ax, runs, labels = [\"model_name\", \"std\"], title = \"Training Loss\", val = False)\n",
    "    val_ax = LossPlot(val_ax, runs, labels = ['model_name', \"std\"], title = \"Validation Loss\", train = False)\n",
    "    fig.tight_layout()\n",
    "    fig.suptitle(f\"Training and Validation Loss, {noise_type.capitalize()} Noise Experiments\", y=1.02)\n",
    "    fig.savefig(f\"{noise_type}_loss_plots.png\")\n"
   ],
   "id": "69744df26d23b43d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "#fianlly, generate a dataframe for test accuracies across all runs\n",
    "import pandas as pd\n",
    "all_runs = []\n",
    "for model_name in models:\n",
    "    for noise_type in noise_types + ['none']:\n",
    "        if noise_type == 'none':\n",
    "            runpath = Path(f\"./runs/{model_name}_none_std0_gamma0_lr{learning_rate}\")\n",
    "            std = 0\n",
    "        for std in stds:\n",
    "            runpath = Path(f\"./runs/{model_name}_{noise_type}_std{std}_gamma{gamma}_lr{learning_rate}\")\n",
    "            #load the rundata in from the json\n",
    "            rundatapath = runpath / \"run_data.json\"\n",
    "            testdatapath = runpath / \"test_data.json\"\n",
    "            with rundatapath.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                run_data = json.load(f)\n",
    "            with testdatapath.open(\"r\", encoding=\"utf-8\") as f:\n",
    "                test_data = json.load(f)\n",
    "            run_data.update(test_data)\n",
    "            all_runs.append(run_data)\n",
    "df = pd.DataFrame(all_runs)\n",
    "df = df[['model_name', 'noise_type', 'std', 'test_acc']] #get only the stuff we want\n",
    "df.to_csv(\"test_accuracies.csv\", index=False)"
   ],
   "id": "2eb5507140c8a582"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "c86c48c3380646b8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
